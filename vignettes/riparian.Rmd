---
title: "riparian"
author: "Erik Rose"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{riparian}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Welcome to the `vignette` for the package `riparian`, a suite of tools designed to help Benton County Community Development staff analyze riparian cover extent and change in cover over time.  This document models the workflow of producing an annual monitoring report for the Benton County riparian monitoring program, and demonstrates how functions in the `riparian` package can make monitoring faster and more efficient for the researcher.

## Step One:  Site Plots

Benton County conducts riparian monitoring whenever new high resolution (1-foot) orthographic imagery becomes available.  Likely, your are reading this because new imagery is about to arrive.

The County currently monitors 54 randomly selected sites along priority corridors, and may add additional sites based upon future permit approvals.  The reason we look at the same 54 sites every year is because we are trying to detect change in cover.  If we looked at a different slew of sites each year, it would be hard to know whether an increase or decrease in cover were due to variation between the sites we selected, or whether vegetation removal or accrual occurred.  Using this method, we can circle individual trees that have gone missing from one year to the next.  Because the sites are randomly selected and representative of conditions in the priority corridor generally, we can be reasonably confident that changes in cover within the sample reflect conditions in the priority corridor.

### Sampling Boxes

If you are starting a fresh session of RStudio, remember to set the path to your personal package library using the .libPaths() function.  Access the polygon shapefile containing the 54 sampling boxes for each site by calling the command:

```{r samples}
# add your personal library path to libPaths
.libPaths( c( 'P:/lib', .libPaths()) )

# access sampling box shapefile
data(samples, package = 'riparian')

# use the raster package to plot spatial data
raster::plot(samples[1,], main = 'Example Sampling Box')
```

In my year, the County collected orthographic imagery in S:/maps/OrthoPhotos, with each year of imagery in a separate folder.  If you are planning on doing a lot of operations on large raster data, then I suggest copying the folder containing the imagery onto an external drive.  This minimizes network traffic for others and speeds performance at your workstation.  If you already know where your sampling boxes are, you can use the `thumbnails()` function to scan over a directory of orthography, and print to a new directory small images cropped to the extent of each sampling box.  This can be a time-saving step if your network is slow or if you are processing a large number of sampling boxes.

### Thumbnail Images

The `thumbnails()` function takes three arguments.  `in_path` is the directory path for orthoimagery.  `out_path` is the directory in which to print the thumbnail images.  `polys` is the sampling box spatial object.

R uses the convention of forward slashes in path names (for instance, the path to my working folder for this project is 'E:/Riparian' and the path to the 2018 imagery is 'E:/ortho2018').  The function expects a character string, so the path name needs to have single or double quotes around it.

```{r thumbnail, eval=FALSE}

# crop small images of the sampling area and print to personal drive
thumbnails(in_path = 'S:/maps/OrthoPhotos/Oregon2018',
           out_path = 'P:/',
           polys = samples)

```
  
### Sample Plots

In order to assess the level of cover over a sample area, we need to project the lines of the sampling box over the new orthographic imagery. The function for printing these plots is called `plot_samples()`.  The full syntax for the function is `plot_samples(in_path, out_path, polys = samples, year, type = 'random', method = 'lm').  Let's break down these arguments one by one.

The first argument is called `in_path` and it is the path to the directory of orthographic imagery.  If you made a directory of thumbnails, use this directory as your `in_path` argument.  The second argument is `out_path`, and specifies the location where the function will print the sample plots.  The third argument, `polys` is the polygon shapefile of sampling boxes.

The `year` argument is an integer that represents the year of orthographic survey.  Do not try geting fancy and entering 'year = 2020jun' or somesuch, because the tools in this package use this number a lot.  Each one is expecting an integer and will break if they do not get one.

The `type` argument, on the other hand, is entirely there for your convenience. You can even safely ignore it.  In 2018, I wanted to know if the level of cover was different in taxlots where the county had issued permits that might affect the riparian zone, compared to the priority corridor as a whole.  I labeled random samples in the riparian corridor as 'random' and samples where the county had issued permits as 'permit'.  The `type` argument is expecting a word of your choice wrapped in quotes.  Other tools in the `riparian` package allow you to filter your sample pool by the `type` names you specify.

### Predicting Cover

The `plot_samples()` function predicts the level of cover in each slice of the sampling box using a linear regression fit to the record of sample observations from 2018, 2016 and 2009. The function adds a green bar to the outer edge of the sample box where it predicts full cover, yellow on slices of partial cover, and red on slices of bare ground.  The function also outputs a spreadsheet containing the predicted values, correctly formatted for later use by other tools in this package.  The spreadsheet output can save you labor by automatically scoring easy calls.

Currently the `plot_samples()` function defaults to using a linear model that expects 4-band imagery (rgbn) as an input.  If you are using 3-band imagery (rgb), then you can tell the function to use a different linear model using the `method` argument.  For 3-band imagery, use the argument `method = 'lm3'`.

The default `polys = 'samples'` means the function looks for an object called `samples` in the current environment, so if you have loaded the data `samples`, then you can omit the third argument.  You can omit the argument names in a function call and R will process the arguments in the order given, but if you omit arguments to use the default, or otherwise provide function arguments out of order, then you need to include the argument name of later arguments in the function call.

```{r plot_samples, eval=FALSE}
library(riparian)

# not run

library(rgdal)
# change the path names
setwd('path_to_shapefile')
samples <- readOGR('mysamples.shp')

# change the path names
# change year to your year
# use method = 'lm3' for 3-band rgb imagery
plot_samples(in_path = 'E:/ortho2018',
             out_path ='E:/Riparian/sites2018',
             polys = samples,
             year = 2018,
             type = 'random',
             method = 'lm')
```
```{r example_slice, echo=FALSE, eval = F}
# example output
pic_path <- system.file('extdata/images', 'eg1.png', pacakge = 'riparian')
knitr::include_graphics('extdata/images/eg1.png')
```


## Scoring Samples

Once you have printed sampling plots for all sites, it is time to score cover extent.

In 2018 I created an excel file called `samples2018.xlsx` to record cover extent for the 2018 annual monitoring report and the 5-year trends and status report.  In order for the functions in `riparian` to work correctly, it is important for you to format your record of observations exactly like the spreadsheet from 2018.  First, let's take a look at that spreadsheet by loading it into the workspace.  The file is located in the extdata folder in csv format.

```{r old_spreadsheet, eval=F}
library(data.table)

# construct the file path to csv
csv_path <- system.file('extdata', 'samples2018.csv', package = 'riparian')

# read the csv in as a data.table
obs <- fread(csv_path)

# examine results
str(obs)
```

You can also examine the data as a native R object, using the `data` function.

```{r native_spreadsheet}
data(samples2018, package = 'riparian')

colnames(samples2018)
```

The spreadsheet has 53 columns, named `id`, `year`, `type` and then numbered 1:50.  Your spreadsheet must adhere to this format, using 53 columns named just so.  The `id` column refers to an individual site id assoiated with each site.  The `year` column specifies the year of observation.  The `type` column is for grouping sites into subsets, such as sites with active permits to track compared to random samples, and may be left blank without consequence.  The columns numbered 1:50 correspond to the numbers on the sample plots printed by `plot_samples()`.  When you are scoring observations, enter the cover score associated with the number on the sampling plot under the column with the same number in the spreadsheet.

The easiest way to adhere to the format requirement manually is to add new observations to the bottom of the 2018 spreadsheet, and save it under a new name.  You can convert the R object into a csv file using the command `write.csv(samples2018, 'myobs.csv')` and fill in your observations using Excel.  If you are using the spreadsheet output from `sample_plots()`, then the spreadsheet is already formatted correctly.

When you are done editing your file in Excel, export it into csv format, which is a tried and true way to share data between programs.  Read the csv into RStudio using the `data.table` package.

```{r csv, eval = F}
# not run
library(data.table)
setwd('path_to_file')

# save R data.table as csv
write.csv(samples2018, 'myobs.csv')

# read csv into R
obs <- fread('myobs.csv')
```

If you are using the predicted cover spreadsheet, then as you inspect each site plot, observe whether each slice is assigned the correct cover class.  Where the predicted class is incorrect, you can update the spreadsheet in Excel.  The column names correspond to the slice numbers on the site plot, and the rows of the spreadsheet will be in the order of the sampling boxes fed to the `plot_samples()` function.  So long as you do not have to do too much manual editing, the prediction feature has the potential to save a lot of time compared to manually scoring each slice from scratch.

Note that while you can cut and paste the corrected scores onto the end of the previous observations in Excel, you can also bind them together easily in R using the native function `rbind()`.

```{r rbind, eval=FALSE}
#not run
library(data.table)
setwd('path_to_file')

# load previous cover score observations
data(samples, package = 'riparian')

# read new observations into R
obs <- fread('samples_2020.csv')

# bind into single data.table
samples_2020 <- rbind(samples, obs)
```



### Subsetting Sites

The `riparian` package takes advantage of several features of the `data.table` package.  The `data.table` is a special class of `data.frame`, with unique syntax for subsetting data.

The first subsetting you will likely want to do is subset by year.  Do this by selecting the column `year` and setting it equal to the target value.  Place this logical test in brackets following the data.table name, and R will return only those observations that pass the test.  Note that logical tests use two equal signs (eg. `year == 2018`).

```{r dt}
library(data.table)
# print summary table of obs by year
samples2018[ , .N, by = year]

# subset year of interst
sub18 <- samples2018[year == 2018]

# verify subset is correct
sub18[ , .N, by = year]
```

The `type` variable is a catch-all for you to define and compare groups within the sample.  The 2018 dataset includes a type value `permit`, which refers to sites with active permits we selected for random monitoring.  We can split the dataset into two groups by using `==` and `!=` (not equal) to divide the data by `type`:

```{r}
# print table of obs by type
samples2018[ , .N, by = type]

# subset permit and nopermit sites
permit_sites <- samples2018[type == 'permit']
nopermit_sites <- samples2018[type != 'permit']

# examine results
permit_sites[ , .N, by = type]
nopermit_sites[ , .N, by = type]
```

To subset by multiples criteria, you can subset sequentially or use logical operators `&` and `|` to nest multiple logical tests.

```{r}

# subset 2018 sites with type trib or permit
sub <- samples2018[year == 2018]
sub <- sub[type == 'trib' | type == 'permit']

# verify subset has correct number of obs
sub[, .N, by = .(year,type)]

# subset 2016 sites with type trib or permit
sub <- samples2018[year == 2016]
sub <- sub[type == 'trib' | type == 'permit']

# verify subset has correct number of obs
sub[, .N, by = .(year, type)]
```


## Plot Cover Extent

The function `plot_cover(csv)` produces a plot of cover extent over all the samples in the object `csv`.  To produce a plot of cover extent for a given year, subset the observations in the data.table by year in the argument to `plot_cover()`.  Optional arguments: the argument `title` sets the name of the .png file printed into the working directory.  The argument `heading` sets a title for the plot (default is blank).  The argument `leg_pos` adjusts the legend position and accepts the arguments `topright`, `topleft`, `bottomright` and `bottomleft`.  You may need to adjust the legend position from its default so it does not cover the data you are trying to display.

```{r plot_cover, fig.show = 'hold'}
library(riparian)
plot_cover(samples2018[year == 2018])
plot_cover(samples2018[year == 2009])
plot_cover(samples2018[year == 2018 & type != 'trib'])


```

## Plot Cover Change

The function `plot_change(csv, year1, year2)` produces a plot of cover extent change from `year1` to `year2` across samples in `csv`.  Here the function does the subsetting for you in the case of year, but you can still subset `csv` by type.  The optional arguments are the same as for `plot_cover`.

```{r plot_change, fig.show='hold'}
plot_change(samples2018, 2016, 2018)
plot_change(samples2018[type != 'trib'], 2016, 2018)
plot_change(samples2018, 2009, 2016)
```


## Clean Permit List

A staff member from the planning department will email you an Excel sheet containing all permits the County has issued since the last monitoring report.  Reading the file into R will require a little extra work preparing the data in Excel.  Open the permit list in Excel, and note that the first column should be `Record Number` and the fifth should read `MapTaxlot #`.  Likely, many of the MapTaxlot numbers will be printed in scientific notation in their cells.  That is a problem, because R will interpret the cells as character vectors, and the ending 7 digits of the MapTaxlot number will be lost.  But first, scroll down and note the first cell where the MapTaxlot number has a little green triangle in the upper left corner.  In order to avoid MapTaxlot numbers displaying in scientific notation, some planning staff display numbers as text in the Excel formatting options.  This is problematic because Excel converts them back to numbers and hence to scientific notation when exporting the file in csv format, and then R interprets it as a character string again.  

Click on the first cell where a MapTaxlot number has the green triangle in the upper left corner, then scroll to the last permit on the sheet and click on its MapTaxlot number while holding the shift key so that you select the entire column below the cell with the green triangle.  Scroll back to the first cell you selected and click on the yellow exclamation point, bringing down a dropdown menu.  From the menu select `Convert to Number`, and watch all the numbers displayed as text revert to scientific notation.

Now scroll to the top of the sheet and select the whole column for `MapTaxlot #`.  Right click on a cell in the highlighted column and click on `Format Cells...`.  The `number` tab should display. Select from the `Category` menu `Number`.  Change `Decimal places` from 2 to 0.  Click `OK`.  With all MapTaxlot numbers converted to number strings and displayed as integers, it is now safe to export the sheet as a csv file to import into R.  Select `Save As`, choose a directory, and from the `Save as type` menu select `CSV (Comma delimited)`.

Read the `csv` file into R using the same `fread` command as for the cover score sheet.

```{r perms, eval = F}
# not run
perms <- fread('mypermits.csv')
```

To demonstrate the functionality of the package, I have included a list of permits from 2013 to 2018 as a data object, which you can access using the `data` function.

```{r perm_list}
data(permits_13to18, package = 'riparian')
colnames(permits_13to18)
```


## Change Tables

The planning staff is concerned with which MapTaxlots have experienced net cover decrease, especially if the decrease is greater than 10%.  The `build_change_table()` function produces a change table designed for use by the planning staff.  The change table ranks sampling sites by mean cover change, all MapTaxlot numbers falling within the sampling box and all permits associated with a MapTaxlot on the permit list.

The full syntax for the function is `build_change_table(csv, year1, year2, polys, lots, permits)`.  The argument `csv` is the record of cover scores for the sampling sites.  The arguments `year1` and `year2` are integers matching values in the `year` column of `csv`.  The argument `polys` is the spatial polygons object of samplings boxes.  The argument `lots` is the polygons object of MapTaxlots, and `permits` is the permit list formatted according to the instructions in the previous section.  The output is a csv file printed to the working directory.

```{r change_table}
build_change_table(csv = samples2018,
                   year1 = 2016,
                   year2 = 2018,
                   polys = samples,
                   lots = prc_lots, 
                   permits = permits_13to18)
```


## Sampler

The time will come when you need to draw new sampling boxes to sample new places.  Typically the County will approve new permits and flag those permits that may result in reduction of cover in the priority corridor.  Your bosses may ask you to include newly permitted areas in your sample.  The `sample_streams()` function generates new sampling boxes along the priority corridor within the area of your choice.  

The full syntax for the function is `sample_streams(n=100, lots=prc_lots, prc=prc_per, strms=prc_strms)`.  The argument `n` is the number of sampling boxes you want to produce, and defaults to 100.  The argument `prc` is the line file along which the function generates random points.  The default is the NHD set of perennial or fish-bearing streams, clipped to the extent of the RR zone, and you should be able to leave the default as is.  

The argument 'strms' defaults to the WSI hydro-enforced drainage layer clipped to the priority corridor.  The WSI hydro-enforced drainage layer is more accurate than the NHD dataset, so the function finds the nearest point on the WSI layer to the random point generated on the NHD layer, and draws the sampling box around that point.  

The argument `lots` is the polygon shapefile that specifies the area within which you want to draw samples, and defaults to the whole priority corridor.  If you have a list of permitted sites to check, then clip the taxlot shapefile down to only those taxlots you want to check, and specify the location of the resulting shapefile in the `lots` argument.

To demonstrate the function, I will generate a random sample of lots within the priority corridor, then draw sample boxes using `sample_streams()`.

```{r sampler}
set.seed(100)
# random lots from the priority corridor
mtls <- as.character(prc_mtls$MapTaxlot[prc_mtls$MapTaxlot != ''])
mtls <- mtls[sample.int(length(mtls), 10)]

random_lots <- prc_mtls[prc_mtls$MapTaxlot %in% mtls, ]

# sample 3 from 10 spots without regard for which lot
samp1 <- sample_streams(n = 3, lots = random_lots)

# sample 10 spots, 1 from each lot
samp2 <- sample_streams(n = 1, lots = random_lots[1,])

for (i in 2:length(random_lots))  {
  samp2 <- rbind(samp2, sample_streams(n = 1, lots = random_lots[i, ]))
}


```

### Bad Sampling Boxes

The sampling tool has known bugs that cause sampling boxes to fail to draw correctly.  I would offer an expected date when these bugs might be resolved, but let's just say I was lucky to get the sampler function working at all.  When you generate a series of sampling boxes, it is possible that many will be good boxes and some will be bad boxes.  My strategy was to create more sampling boxes than I needed, and then to delete bad or unwanted boxes from the resulting spatial object.

R recognizes the sampling boxes as spreadsheets with associated spatial data.  Each sampling box is a row of data, and you can delete unwanted rows as shown in the code snippet below.  Note the use of the concatenate function `c()` to delete multiple samples at once.

```{r bad_box}
# remove unwanted sample from polygons object
samp <- samp1[ , -2]
samp <- samp2[ , -c(3,7:9)]

library(sp)
plot(bad_box, main = 'Bad Sampling Box')

```


### Adding New Samples

Suppose that you have a shapefile saved in your directory of samples over areas where the county has issued permits that may impact the riparian corridor.  Further suppose that you have used the `sampler` function to generate a set of new sampling boxes, covering sites where the county has issued permits in the intervening period since the last survey.  Now you want add the new sampling boxes to the shapefile with the old ones, so as to keep them all in one place.

The function for cleanly joining new polygons to old polygons is called `poly_to_poly()`.  `poly_to_poly()` will join any number of polygon objects into a single unified object.  Pass the polgyons of interest to the function within a list.

```{r poly_to_poly}
# wrap polygons you want to merge in a list
poly_list <- list(samples, samp1, samp2)

# pass the list to the function to create a single polygons object
all_samples <- poly_to_poly(poly_list)
```

You can export a polygons object into a shapefile using the `writeOGR()` function from the `rgdal` package.  Since there is a lot of good online documentation for that package, I will present an example of how to export your data using the function in the code snippet below, but I will not explain the nuts and bolts in detail.  Alternatively, you can save your work as a native R object (.rds format).  This is the recommended method is you are storing objects for projects that are in progress, but when you have a finished product it is best practice to export it to a shapefile, because the county GIS standard is ArcGIS.  If you save it only as a native R object, the rest of the staff may be unable to use it on their software.

```{r save, eval = F}
library(rgdal)

# export to shapefile
rgdal::writeOGR(obj = all_samples, 
                dsn = 'path_to_my_dir',
                layer = 'all_samples',
                driver = 'ESRI Shapefile')

# save as native R object
save(all_samples, 'all_samples_2020.rds')  # you must include the .rds extention

# load a saved object
load('all_samples_2020.rds')

```


## Predicted Cover

The `pred_cover()` function predicts the level of vegetative cover using an NDVI-based model.  Over a given spatial polygon, the function predicts the level of cover based upon orthographic imagery, and prints a new raster of predicted cover values to a specified directory `out_path`.

The full syntax of the function is `pred_cover(polys, in_path, out_path, rgb_path = NULL, cir_path = NULL, buff = prc_buff)`.  The argument `polys` is the spatial polygon object of taxlots over which you want to predict cover.  This function is designed to default to 4-band imagery, so the argument `in_path` is a character string representing a directory path to 4-band imagery.  In 2016, the County received 3-band RGB and CIR imagery.  If this is the case for you, set the arguments `rgb_path` and `cir_path` to directory paths to the RGB and CIR imagery respectively, and do not specify an argument for `in_path`.  The argument `buff` is the riparian buffer for the WSI hydro-enforced layer clipped to the Rural Residential zone.


```{r pred_cover, eval=F}
# not run
# change directory paths to point to your data

pred_cover(random_lots, out_path = 'E:/Riparian/pred_2016/',
           rgb_path = 'S:/maps/OrthoPhotos/Hexagon2016/RGB/',
           cir_path = 'S:/maps/OrthoPhotos/Hexagon2016/CIR/')



pred_cover(random_lots, 'E:/ortho2018', 'E:/Riparian/pred_2018/')

# predict cover change
pred_change('E:/Riparian/pred_2016', 'E:/Riparian/pred_2018', 'E:/Riparian/chng_16to18')

```

## Predicted Cover Change

The `pred_change()` function predicts the level of change in riparian cover based upon the output of the `pred_cover()` function.  The full syntax is `pred_change(year1_path, year2_path, out_path)`.  The argument `year1_path` is a character string specifying a directory path to the rasters produced by `pred_cover()` for year 1, and the argument `year2_path` is a character string specifying a directory path to the rasters produced by `pred_cover()` for year 2.  The argument `out_path` specifies the directory to which the function will print rasters with values of predicted change in cover.

Produce a table summarizing the predicted change in cover using the function `pred_change_report()`.  The full syntax is `pred_change_report(chng_path, year1_path, year2_path, permits = permits_13to18, lots = prc_lots, title = 'pred_chng_table.csv')`.  The argument `chng_path` is the path to the directory of predicted change rasters produced by `pred_change()`.  The arguments `year1_path` and `year2_path` specify the paths to the directories of predicted cover rasters output by `pred_cover()` for year 1 and year 2 respectively.  The argument `permits` is the same csv file of approved permits you used to produce change tables of randomly selected sites.  The default is set to the list of permits from 2013 to 2018 to help demonstrate the functionality of the package in this vignette.  The argument `lots` defaults to a shapefile of taxlots in the priority corridor, and the function uses this file to search for which taxlot a given area of the priority corridor lies within.  The argument `title` specifies the title of the predicted change table, which should end in '.csv', and prints to the working directory.

```{r change_report, eval=F}
# not run
# change directory paths to point to your data

pred_change_report(chng_path = 'E:/Riparian/chng_16to18/', 
                   year1_path = 'E:/Riparian/pred_2016/', 
                   year2_path = 'E:/Riparian/pred_2018/')

```

